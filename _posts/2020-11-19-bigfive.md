---
layout: post
title: Big 5 Personality Trait Predictor
subtitle: My attempt to predict a person's 5th personality trait given the other 4
cover-img: /assets/img/big5.jpg
thumbnail-img: /assets/img/confusion.png
share-img: /assets/img/confusion.png
---

#### For this project, I looked for a data set that had to do with psychology, as that's an area I am quite interested in. On Kaggle I found a very comprehensive data set about the Big 5 Personality Test, with 1 million observations and 110 features. The test asks 50 questions, 10 for each trait, and takes the averages of those 10 to place you on a scale for that trait. The 5 traits are extraversion, neuroticism, agreeableness, conscientiousness and openness.

## My research question:
### Can I predict the 5th personality trait of a person given the answers to the questions of the other 4?

The usefulness of knowing this is questionable. If you can ask a person the first 40 quesitons, it should be simple enough to ask the last 10. However, I believe it would be nice to know if there is a relationship there. If yes, we could say many people do indeed fit into nice categories as so many think. With no relationship there, we could conclude people are much more complex than we thought, and don't fit into nice litte boxes.

----------------------------------------------------------------------------------

The questions are answered with integers between 1 and 5, and therefore the scale for a personality trait is between 1 and 5. It should be a simple regression problem. Unfortunately, with 40 features and a training set with 800,000 observations, my machine couldn't really handle such a regression problem. Thankfully a classification problem is much less intensive. So I turned it into one, where 0 is the bottom third of the data, 1 is the middle third, and 2 is the top third. This would mean, to use extraversion as an example, 0 for introverted, 2 for extraverted, and 1 for a bit of both.

After much trial and error, I decided to use an XGBClassifier model for this problem. I trained 5 models, 1 for each trait, and got between 50% and 57% accuacy across all of them. At first glance, this doesn't seem great. It is an improvement over just gueessing, but only by about 20%. However, taking a look at a confusion matrix tells an interesting story.

![matrix](/assets/img/confusion.png)

We can see from this matrix that when predicting one of the two ends, the model is pretty darn accurate. It's when it tries to predict someone that falls in the middle that it ends up just guessing. If you've ever taken a test like this, often they ask you to avoid giving a neutral answer (3), and instead be decisive. I imagine this is the reason. If a person is decisive in their answers, it makes for a clear result for the algorithm to interpret. When a person is somewhere in the middle on the 4 given traits, the algorithm doesn't have much to go on, and tries to guess. Again, this is just a hypothesis. There could be any number of reasons for this result, but they are fascinating to see nonetheless.
